{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICPSR Dataset Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox, Label\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import community\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "datasets = pd.read_json('data/data_sets.json')\n",
    "publications = pd.read_json('data/publications.json')\n",
    "datasets['title_lower'] = datasets['title'].str.lower()\n",
    "publications['title_lower'] = publications['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c3514f04e74aef9f3012e7bbe62b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='By', options=('Dataset Title', 'Dataset ID', 'Publication Title', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "\n",
    "def showDatasets(By = ['Dataset Title', 'Dataset ID', 'Publication Title', 'Publication ID', 'DOI'], Search=\"ANES 1952\"):\n",
    "    column = {\n",
    "        'Dataset Title': 'title_lower',\n",
    "        'Dataset ID': 'data_set_id',\n",
    "        'Publication Title': 'title_lower',\n",
    "        'Publication ID': 'publication_id',\n",
    "        'DOI': 'unique_identifier'\n",
    "    }\n",
    "    slist = Search.lower().split(',')\n",
    "#     return slist\n",
    "    try:\n",
    "        if(By == 'Dataset Title'):\n",
    "            return datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].str.contains('|'.join(slist))]\n",
    "        elif (By == 'Dataset ID'):\n",
    "            tmp = datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].isin([int(n) for n in slist])]\n",
    "            sorter = pd.DataFrame([int(n) for n in slist], columns=['data_set_id'])\n",
    "            return pd.merge(sorter, tmp, how='left', on='data_set_id')\n",
    "        elif (By == 'Publication Title'):\n",
    "            return publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].str.contains('|'.join(slist))]\n",
    "        elif (By == 'Publication ID'):\n",
    "            tmp = publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].isin([int(n) for n in slist])]\n",
    "            sorter = pd.DataFrame([int(n) for n in slist], columns=['publication_id'])\n",
    "            return pd.merge(sorter, tmp, how='left', on='publication_id')\n",
    "        elif (By == 'DOI'):\n",
    "            sl\n",
    "            tmp = datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].str.contains('|'.join(slist))]\n",
    "            tmp2 = publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].str.contains('|'.join(slist))]\n",
    "            return tmp if tmp.shape[0]>0 else tmp2            \n",
    "    except Exception as e:\n",
    "        print(\"ERROR \"+e)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "\n",
    "def read_json_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)\n",
    "def generatePairs(firstnode, allDatasets):\n",
    "    return [(firstnode, i) for i in allDatasets]\n",
    "def getSimilarity(node, g, metric):\n",
    "    allDatasets = [i for i in g.nodes if(str(i).startswith('data'))]\n",
    "    \n",
    "    if (node.startswith('d')):\n",
    "        titleID = df_datasets.title_id[df_datasets.data_set_id == int(node.replace('data_', ''))]\n",
    "        filterSim = list(df_datasets.data_set_id[df_datasets.title_id == titleID.iloc[0]])\n",
    "        filterSim = ['data_'+str(i) for i in filterSim]\n",
    "\n",
    "        filtered = [i for i in allDatasets if i not in filterSim]\n",
    "    else:\n",
    "        filtered = allDatasets\n",
    "    pairs = generatePairs(node, filtered)\n",
    "\n",
    "    if metric == 'Hopcroft':\n",
    "        preds = nx.ra_index_soundarajan_hopcroft(g, pairs)\n",
    "    elif metric == 'Jaccard':\n",
    "        preds = nx.jaccard_coefficient(g, pairs)\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "    res = []\n",
    "    for u, v, p in preds:\n",
    "        if p > 0.0:\n",
    "            res.append((u,v,p))\n",
    "    return res\n",
    "def getRecommendations(i, G, metric = 'Hopcroft'):\n",
    "    tmp = getSimilarity(i, G, metric)\n",
    "    print(\"Fetching dataset ID: %s \\nCalculating %s scores for %s/%s datasets\"%(i, metric, len(tmp),len(allDatasets)))\n",
    "    if len(tmp)>0:\n",
    "        df = pd.DataFrame(tmp, columns=['x', 'data_set_id', 'score']).sort_values(by=['score'], ascending=False).reset_index()\n",
    "        df.data_set_id = [int(i.replace('data_', '')) for i in df.data_set_id]\n",
    "\n",
    "        ids = df.data_set_id[:N]\n",
    "        ids = df_datasets[df_datasets.data_set_id.isin(ids)]\n",
    "        ids = ids.groupby('title_id').first().reset_index()\n",
    "\n",
    "        res = pd.merge(ids, df, how='inner', on='data_set_id').sort_values(by=['score'], ascending=False).reset_index()\n",
    "        return res[['data_set_id', 'score', 'degree_centrality']].iloc[:10]\n",
    "\n",
    "G = read_json_file('data/network_json.json')\n",
    "\n",
    "partition = community.best_partition(G)\n",
    "for i in G.nodes:\n",
    "    G.nodes[i]['community'] = partition.get(i)\n",
    "\n",
    "titles = datasets.title.str.lower()\n",
    "titles = titles.str.replace('[^a-zA-Z]', '')\n",
    "\n",
    "df_titles = pd.DataFrame(set(titles)).reset_index()\n",
    "df_titles.columns = ['title_id','title_unique']\n",
    "df_titles.title_id = ['title_'+str(i) for i in df_titles.index]\n",
    "\n",
    "df_datasets = datasets.copy()\n",
    "df_datasets['title_unique'] = df_datasets['title'].str.lower()\n",
    "df_datasets.title_unique = df_datasets.title_unique.str.replace('[^a-zA-Z]', '')\n",
    "df_datasets = pd.merge(df_datasets, df_titles, on='title_unique', how='left')\n",
    "\n",
    "allDatasets = [i for i in G.nodes if(str(i).startswith('data'))]\n",
    "allPubs = [i for i in G.nodes if(str(i).startswith('pub'))]\n",
    "N = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90070cd82b46239377bef0062a580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Press to generate dataset recommendations')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f83663d7454a2db7da4443fcc7b61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Entity Type', index=1, options=('Publication Paper', 'Dataset', 'Keyword'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04de434e82d04918b8afd10452976507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "btn = widgets.Button(description = \"Recommend Me\")\n",
    "typeDD = widgets.Dropdown(\n",
    "    options = ['Publication Paper', 'Dataset', 'Keyword'],\n",
    "    value = 'Dataset',\n",
    "    description = 'Entity Type'\n",
    ")\n",
    "searchBar = widgets.Text(\n",
    "    value = '',\n",
    "    placeholder = 'Insert Keyword/ID'\n",
    ")\n",
    "typeDict = {\n",
    "    'Publication Paper': 'pub_',\n",
    "    'Dataset': 'data_',\n",
    "    'Keyword': ''\n",
    "}\n",
    "metric = widgets.Dropdown(\n",
    "    options = ['Hopcroft', 'Jaccard'],\n",
    "    value = 'Jaccard'\n",
    ")\n",
    "btn_reset = widgets.Button(description = 'Reset')\n",
    "display(Label('Press to generate dataset recommendations'))\n",
    "# display(HBox([typeDD, searchBar,btn, btn_reset]))\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def button_handler(btn):\n",
    "    if typeDD.value == 'Keyword':\n",
    "        print('Feature unavailable')\n",
    "        return\n",
    "    elif (typeDD.value == 'Dataset') & (searchBar.value == ''):\n",
    "        sampleDataset = random.sample(allDatasets, 1)\n",
    "    elif (typeDD.value == 'Publication Paper') & (searchBar.value == ''):\n",
    "        sampleDataset = random.sample(allPubs, 1)\n",
    "    else:\n",
    "        sampleDataset = [typeDict[typeDD.value]+searchBar.value]\n",
    "    for i in sampleDataset:\n",
    "        res = getRecommendations(i, G, metric.value)\n",
    "        display(\",\".join(str(i) for i in res.data_set_id[:10]))\n",
    "        display(res)\n",
    "def clear_output(btn_reset):\n",
    "    out.clear_output()\n",
    "btn.on_click(button_handler)\n",
    "btn_reset.on_click(clear_output)\n",
    "\n",
    "display(HBox([typeDD, searchBar, metric, btn]))\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS Base",
   "language": "python",
   "name": "ds_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
