{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICPSR Dataset Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox, Label\n",
    "from networkx.readwrite import json_graph\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "\n",
    "import RecommendationSystem as rs\n",
    "import NetworkBuilder as nb\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "datasets = pd.read_json('data/train_test/data_sets.json')\n",
    "publications = pd.read_json('data/train_test/publications.json')\n",
    "datasets['title_lower'] = datasets['title'].str.lower()\n",
    "publications['title_lower'] = publications['title'].str.lower()\n",
    "\n",
    "def readNX(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)\n",
    "\n",
    "G = nb.buildG()\n",
    "G = nb.addCommunity(G)\n",
    "# G = readNX('data/network_v2.5_contract.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24487f9c578e41c88ad993641d0eab19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='By', options=('Dataset Title', 'Dataset ID', 'Publication Title', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "\n",
    "def showDatasets(By = ['Dataset Title', 'Dataset ID', 'Publication Title', 'Publication ID', 'DOI'], Search=\"ANES 1952\"):\n",
    "    column = {\n",
    "        'Dataset Title': 'title_lower',\n",
    "        'Dataset ID': 'data_set_id',\n",
    "        'Publication Title': 'title_lower',\n",
    "        'Publication ID': 'publication_id',\n",
    "        'DOI': 'unique_identifier'\n",
    "    }\n",
    "    slist = Search.lower().split(',')\n",
    "#     return slist\n",
    "    try:\n",
    "        if(By == 'Dataset Title'):\n",
    "            return datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].str.contains('|'.join(slist))]\n",
    "        elif (By == 'Dataset ID'):\n",
    "            tmp = datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].isin([int(n) for n in slist])]\n",
    "            sorter = pd.DataFrame([int(n) for n in slist], columns=['data_set_id'])\n",
    "            return pd.merge(sorter, tmp, how='left', on='data_set_id')\n",
    "        elif (By == 'Publication Title'):\n",
    "            return publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].str.contains('|'.join(slist))]\n",
    "        elif (By == 'Publication ID'):\n",
    "            tmp = publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].isin([int(n) for n in slist])]\n",
    "            sorter = pd.DataFrame([int(n) for n in slist], columns=['publication_id'])\n",
    "            return pd.merge(sorter, tmp, how='left', on='publication_id')\n",
    "        elif (By == 'DOI'):\n",
    "            sl\n",
    "            tmp = datasets[['data_set_id', 'unique_identifier','title', 'description']].loc[datasets[column[By]].str.contains('|'.join(slist))]\n",
    "            tmp2 = publications[['publication_id', 'unique_identifier','title']].loc[publications[column[By]].str.contains('|'.join(slist))]\n",
    "            return tmp if tmp.shape[0]>0 else tmp2            \n",
    "    except Exception as e:\n",
    "        print(\"ERROR \"+e)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "military records\n",
    "outpatient care\n",
    "infant mortality\n",
    "ethnic tensions\n",
    "urban decline\n",
    "insurance coverage\n",
    "employment discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be99f4914c74282bd6d4c8f8b50569c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Search_By', options=('Keyword', 'Dataset', 'Publication Paper'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = ['Keyword', 'Dataset', 'Publication Paper']\n",
    "metric = ['Cosine', 'Jaccard', 'Adamic-Adar', 'Hopcroft']\n",
    "\n",
    "@interact\n",
    "def showRecommendations(category=typeDD, Search='', Metric=metric, live=False):\n",
    "    if live:\n",
    "        return rs.getRecommendations(Search_By, Search, Metric, G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rich Context",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
